{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NuQten/Projet_IArecognizing_bolt_nut/blob/main/MECA653_Project_English_Version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW_ryhlz2AaY"
      },
      "source": [
        "# Automized Quality Control : an AI that recognizes a screw from a nut\n",
        "\n",
        "**Authors:  Elisa LABALLERY, BenoÃ®t DAVID, Quentin CONANEC**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bLxsz-Qk2Aaa"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "from skimage import io\n",
        "from scipy import ndimage\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import pandas as pd\n",
        "%matplotlib nbagg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvI-C-X52Aab"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "\n",
        "## Why this project ?\n",
        "\n",
        "\n",
        "This project can be very interesting regarding industrial applications.\n",
        "\n",
        "In fact, it could help automate quality control by ensuring that the right components are used and assembled by an accurate identification of, in this case, bolts and nuts.\n",
        "\n",
        "Besides, it can positivily develop inventory management : it is able to assist in keeping track of components in warehouses and reducing errors of misplacement or misidentification of tools.\n",
        "\n",
        "Finally, with no doubt, an AI brings efficiency gains. This project can lead to faster production and execution time, along as lower costs as it may work without fatigue.\n",
        "\n",
        "In addition, this project is obviously interesting in matter of Big Data applications. The ability to differentiate similar objects means the AI can process and learn from large datasets, improving over time and adapting to new specifications.\n",
        "\n",
        "\n",
        "## State of the art\n",
        "\n",
        "\n",
        "To modelize an IA working in a factory and trained to recognize bolts from nuts, we had to import a graphic database of different bolts and nuts. You will have to import this database in the files section : content > database to get the code to work effectively.\n",
        "\n",
        "\n",
        "## Numerical challenges\n",
        "\n",
        "\n",
        "This project assesses three key points of coding : image processing, machine learning and prediction models.\n",
        "\n",
        "First, we will have to manipulate classes and functions to segment, normalize and binarize our imported images.\n",
        "\n",
        "Then, we are going to create a neural network model for classifying our images using transfer learning (with the VGG16 architecture).\n",
        "\n",
        "Finally, we are going to test our model on an image database. The predictions made by the model are based on the learned parameters of the neural network. If the model was not trained properly or if it has limitations in recognizing certain features of nuts and screws, the predictions may not be accurate.\n",
        "\n",
        "\n",
        "# Coding\n",
        "\n",
        "Now, we will guide you in the process of this coding project. First, please run these little modules so that everything is settled !"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import morphology, transform, feature, measure, segmentation, color, io, filters\n",
        "import skimage as ski\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy import ndimage\n",
        "import random\n"
      ],
      "metadata": {
        "id": "3z0EnuYf8a1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c2ac532-cb3d-4e9c-ec3b-3b350720e7ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Processing\n",
        "\n",
        "First, let's get through the image processing part.\n",
        "\n",
        "The best way to deal with this task is to create a class.\n",
        "It's main purpose is to load images, convert them to grayscale, apply gradient filters, segment them based on pixel intensity, normalize the images to a specific dimension, and finally binarize them.\n",
        "\n",
        "This is useful, in particular, regarding the efficiency of the machine learning model we are going to create afterwards.\n",
        "\n",
        "Commentaries complete the code for further understanding."
      ],
      "metadata": {
        "id": "cWq2nCc-olQx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-F-ER4PP2Aac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09193555-e1a2-43cb-fd9e-824b78464e3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The file is not in ['.config', 'drive', 'sample_data'] , retry !\n"
          ]
        }
      ],
      "source": [
        "class Image_ia():\n",
        "\n",
        "    def __init__(self, path: str, seuil=0.025, dimension=100, label_bg=2, label_connect=2, distance_expanse=20) -> None:\n",
        "        \"\"\"Initializes the image to be used by the AI onwards.\n",
        "\n",
        "        Args:\n",
        "            path (str): Path to the image file.\n",
        "            seuil (float, optional): Threshold between background (bg) and foreground (fg). Value ranges between [0;1]. Defaults to 0.025.\n",
        "            label_bg (int, optional): Includes the background in the labeling or not. Acceptable values are {None, 1, 2}. Defaults to 2.\n",
        "            label_connect (int, optional): Number of pixels between two points to connect them together. Defaults to 2.\n",
        "            dimension (int, optional): Dimension of the final image. Defaults to 100.\n",
        "        \"\"\"\n",
        "        # Image Characteristics\n",
        "        self.path = path\n",
        "        self.seuil = seuil\n",
        "        self.dimension = dimension\n",
        "        self.label_bg = label_bg\n",
        "        self.label_connect = label_connect\n",
        "        self.distance_expanse = distance_expanse\n",
        "\n",
        "        # Different images\n",
        "        self.img_whole = ski.io.imread(path)\n",
        "        self.gray_img_whole = ski.color.rgb2gray(self.img_whole)\n",
        "        self.gradient_img_whole = ski.filters.sobel(self.gray_img_whole)\n",
        "        self.imgs = self.__segmentation()\n",
        "        self.gray_imgs = [ski.color.rgb2gray(img) for img in self.imgs]\n",
        "        self.normalize_gray_imgs = [transform.resize(img, (self.dimension, self.dimension), anti_aliasing=True) for img in self.gray_imgs]\n",
        "        self.normalize_gradient_imgs = [ski.filters.sobel(img) for img in self.normalize_gray_imgs]\n",
        "        self.normalize_bin_imgs = [bin_image(img) for img in self.normalize_gradient_imgs]\n",
        "\n",
        "    def __segmentation(self):\n",
        "        \"\"\"Divides the main image according to the number of parts present in the photo.\n",
        "\n",
        "        Returns:\n",
        "            list : Returns a list of different images.\n",
        "        \"\"\"\n",
        "        # Segment the image based on the gradient filter\n",
        "        labels = labelisation(self.gradient_img_whole, self.seuil, self.label_bg, self.label_connect)\n",
        "\n",
        "        # Remove labels\n",
        "        labels, enum_label = remove_label(labels)\n",
        "\n",
        "        # Expand the labels\n",
        "        label_expanded = ski.segmentation.expand_labels(labels, distance=self.distance_expanse)\n",
        "\n",
        "        # Create images of different labels\n",
        "        imgs = create_img_label(label_expanded, enum_label, self.img_whole)\n",
        "        for img in imgs:  # Iterate through the different images to remove the useless ones (black/white)\n",
        "            if img.max == 0 or img.min == 255:\n",
        "                imgs.remove(img)\n",
        "\n",
        "        # Return the images of different labels\n",
        "        return imgs\n",
        "\n",
        "\n",
        "def labelisation(img, seuil=0.025, label_bg=2, label_connect=2):\n",
        "    \"\"\"Differentiates the different zones of each component.\n",
        "\n",
        "    Args:\n",
        "        img (array): image filtered with the Sobel filter\n",
        "        seuil (float, optional): Threshold between bg and fg. Value ranges between [0;1]. Defaults to 0.025.\n",
        "        label_bg (int, optional): Includes the bg in the labeling or not. Acceptable values are {None, 1, 2}. Defaults to 2.\n",
        "        label_connect (int, optional): Number of pixels between two points to connect them together. Defaults to 2.\n",
        "\n",
        "    Returns:\n",
        "        array : Returns an image with different labels.\n",
        "    \"\"\"\n",
        "    # Create an image of the same size\n",
        "    markers = np.zeros_like(img)\n",
        "\n",
        "    # Identify the foreground and background using the chosen threshold\n",
        "    foreground, background = 1, 2\n",
        "    markers[img < seuil] = background\n",
        "    markers[img > seuil] = foreground\n",
        "\n",
        "    # Apply segmentation\n",
        "    segmentation_result = ski.segmentation.watershed(img, markers)\n",
        "\n",
        "    # Identify the different labels\n",
        "    labels = measure.label(segmentation_result == foreground, background=label_bg, connectivity=label_connect)\n",
        "\n",
        "    # Return an image with the labels\n",
        "    return labels\n",
        "\n",
        "\n",
        "def remove_label(labels, pixel_min=1000):\n",
        "    \"\"\"Removes labels that are too small.\n",
        "\n",
        "    Args:\n",
        "        labels (array): image of different labels\n",
        "        pixel_min (int, optional): minimum number of pixels required to keep a label. Defaults to 1000.\n",
        "    Returns:\n",
        "        (array, dict) : Returns an image with labels removed and a dictionary with their characteristics.\n",
        "    \"\"\"\n",
        "    # Basic characteristics\n",
        "    enum_label = {}  # Store the characteristics of the labels\n",
        "    x, y = labels.shape  # Dimensions of the image\n",
        "    get_number = True  # Check if the label exists\n",
        "    n = 0  # Number of points\n",
        "    is_number = 1  # Define the label to be tested\n",
        "\n",
        "    # Loop through the labels one by one\n",
        "    while get_number == True:\n",
        "        list_i = []  # List of pixels in i\n",
        "        list_j = []  # List of pixels in j\n",
        "        n = 0       # Number of pixels\n",
        "\n",
        "        for i in range(x):  # Loop through the image of labels\n",
        "            for j in range(y):\n",
        "                if labels[i][j] == is_number:  # Check if the pixel belongs to the label\n",
        "                    # Add the pixel to the list\n",
        "                    n += 1\n",
        "                    list_i.append(i)\n",
        "                    list_j.append(j)\n",
        "\n",
        "        if n == 0:  # If 0 points detected, then there are no more labels, close the loop\n",
        "            get_number = False\n",
        "        elif n <= pixel_min:  # If fewer pixels than desired, then delete the label\n",
        "            for i, j in zip(list_i, list_j):\n",
        "                labels[i][j] = 0\n",
        "        else:  # Otherwise, store the characteristics of the label\n",
        "            enum_label[is_number] = {'i_min': min(list_i),\n",
        "                                     'i_max': max(list_i),\n",
        "                                     'j_min': min(list_j),\n",
        "                                     'j_max': max(list_j),\n",
        "                                     'nb_point': n\n",
        "                                    }\n",
        "\n",
        "        # Increment by 1 to test the next label\n",
        "        is_number += 1\n",
        "\n",
        "    return labels, enum_label  # Return the remaining labels and their characteristics\n",
        "\n",
        "\n",
        "def create_img_label(labels, enum_label, image):\n",
        "    \"\"\"Creates a new image for each label and returns a list of them.\n",
        "\n",
        "        Args:\n",
        "            enum_label (dict): characteristics of each label\n",
        "            label_expanded (array): image of desired labels\n",
        "\n",
        "        Returns:\n",
        "            list : Returns a list of new images.\n",
        "    \"\"\"\n",
        "    # Create the list that will contain the future images\n",
        "    new_pict = []\n",
        "\n",
        "    # Loop for the number of labels (and therefore photos)\n",
        "    for number_label, label in enum_label.items():\n",
        "\n",
        "        dimension = max(label['i_max']-label['i_min'],  # Get the dimensions of the future image\n",
        "                        label['j_max']-label['j_min'])\n",
        "        segmented_image = np.zeros((dimension, dimension, 3), dtype='uint8')  # Create a black image with the dimensions\n",
        "\n",
        "        # Replace the black image with the desired one\n",
        "        for i in range(label['i_min'], label['i_max']):  # Iterate through the location of the image in the base one\n",
        "            for j in range(label['j_min'], label['j_max']):\n",
        "                if labels[i][j] != number_label:  # If the pixel does not belong to the label, then make it black\n",
        "                    segmented_image[i - label['i_min']][j - label['j_min']] = np.array([0, 0, 0], dtype='uint8')\n",
        "                else:  # Otherwise, it takes the value of the initial image\n",
        "                    segmented_image[i - label['i_min']][j - label['j_min']] = image[i][j]\n",
        "\n",
        "        # Replace the black pixels to obtain a uniform background\n",
        "        for i in range(dimension):\n",
        "            for j in range(dimension):\n",
        "                if np.array_equal(segmented_image[i][j], np.array([0, 0, 0]), equal_nan=False):\n",
        "                    if i == 0:\n",
        "                        segmented_image[i][j] = segmented_image[i][j-1]\n",
        "                    elif j == 0:\n",
        "                        segmented_image[i][j] = segmented_image[i-1][j]\n",
        "                    else:\n",
        "                        segmented_image[i][j] = segmented_image[i-1][j-1]\n",
        "\n",
        "        # Add the image to the list of images\n",
        "        new_pict.append(segmented_image)\n",
        "\n",
        "    # Return the list of images\n",
        "    return new_pict\n",
        "\n",
        "\n",
        "def bin_image(img, seuil=0.025):\n",
        "    \"\"\"Binarizes an image.\n",
        "\n",
        "    Args:\n",
        "        img (array): image to binarize\n",
        "        seuil (float, optional): Binarization threshold [0;1]. Defaults to 0.025.\n",
        "\n",
        "    Returns:\n",
        "        array : Returns a binarized image.\n",
        "    \"\"\"\n",
        "    # Create an image of the same size\n",
        "    markers = np.zeros_like(img)\n",
        "\n",
        "    # Identify the foreground and background using the chosen threshold\n",
        "    foreground, background = 1, 2\n",
        "    markers[img < seuil] = background\n",
        "    markers[img > seuil] = foreground\n",
        "\n",
        "    # Apply binarization\n",
        "    img_watershed = ski.segmentation.watershed(img, markers)\n",
        "\n",
        "    # Iterate through the image\n",
        "    for i in range(img_watershed.shape[0]):\n",
        "        for j in range(img_watershed.shape[1]):\n",
        "            if img_watershed[i][j] == 2:  # If the pixel belongs to the foreground, make it black\n",
        "                img_watershed[i][j] = 1.\n",
        "            else:  # If the pixel belongs to the background, make it white\n",
        "                img_watershed[i][j] = 0.\n",
        "\n",
        "    # Return the binarized image\n",
        "    return img_watershed\n",
        "\n",
        "\n",
        "def list_files_recursively(directory):\n",
        "    \"\"\"Returns a list of files present in the hierarchy\n",
        "    starting from the access path.\n",
        "    \"\"\"\n",
        "    list_path = []\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            list_path.append(os.path.join(root, file))\n",
        "    return list_path\n",
        "\n",
        "\n",
        "def save_normalize_bin_img(path, dimension):\n",
        "    \"\"\"Saves all the photos in a dimension from\n",
        "        the image files found in the hierarchy.\n",
        "    \"\"\"\n",
        "    # List of all access paths to an image\n",
        "    liste = list_files_recursively(path)\n",
        "\n",
        "    nut = 1\n",
        "    screw = 1\n",
        "    os.mkdir(f'data_base_bin_{dimension}')\n",
        "    os.mkdir(f'data_base_bin_{dimension}/screws')\n",
        "    os.mkdir(f'data_base_bin_{dimension}/nuts')\n",
        "\n",
        "    for path in liste:\n",
        "        img = Image_ia(path, dimension=dimension)\n",
        "        for bin in img.normalize_bin_imgs:\n",
        "            # Save the binary image\n",
        "            if \"screws\" in path:\n",
        "                name = f'data_base_bin_{dimension}/screws/{screw}_img_bin_screw_{dimension}.png'\n",
        "                ski.io.imsave(name, (bin * 255).astype('uint8'))\n",
        "                screw += 1\n",
        "            else:\n",
        "                name = f'data_base_bin_{dimension}/nuts/{nut}_img_bin_nut_{dimension}.png'\n",
        "                ski.io.imsave(name, (bin * 255).astype('uint8'))\n",
        "                nut += 1\n",
        "            print(name)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    path = 'boulon_entier.jpg'  # Access path of the image\n",
        "    img = Image_ia(path)\n",
        "\n",
        "    # Display all states of the image\n",
        "    plt.figure()\n",
        "    plt.title('whole image (color)')\n",
        "    plt.imshow(img.img_whole)\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title('whole image (gray)')\n",
        "    plt.imshow(img.gray_img_whole, cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title('whole image (gradient)')\n",
        "    plt.imshow(img.gradient_img_whole, cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title('segmented image (color)')\n",
        "    plt.imshow(img.imgs[0])\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title('segmented image (gray)')\n",
        "    plt.imshow(img.gray_imgs[0], cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title('segmented normalized image (gray)')\n",
        "    plt.imshow(img.normalize_gray_imgs[0], cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title('segmented normalized image (gradient)')\n",
        "    plt.imshow(img.normalize_gradient_imgs[0], cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title('segmented normalized image (binary)')\n",
        "    plt.imshow(img.normalize_bin_imgs[0], cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "    # Save all images in a dimension\n",
        "    path = 'data_base'  # Access path of the images\n",
        "    save_normalize_bin_img(path, 224)  # Save the images in a folder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine learning\n",
        "\n",
        "Now, we have to create an AI that manages to recognizes a screw from a nut and automatically saves the image in a folder regarding wether it's one or another.\n",
        "\n",
        "This code defines, trains, and evaluates a neural network model for classifying our images using transfer learning with the VGG16 architecture.\n",
        "\n",
        "To be precise, a neural network is very useful in machine learning as it is effective for image classification tasks. Besides, the VGG16 architecure contains 16 layers and the last layers are removed, so that new layers are added for classifying nuts and screws specifically, leading to an ability to extract useful feature whilst adapting it to our specific case.\n",
        "\n",
        "Please find useful commentary in the code for further understanding."
      ],
      "metadata": {
        "id": "irRuOOkZ0zZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "CLASS_NAMES = ['nut', 'screw'] #List of possibilities\n",
        "dimension = 224 #Image dimension\n",
        "batch_size = 32\n",
        "path = f'data_base_color_{dimension}' #Path to the database\n",
        "\n",
        "#Load training images\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  path,\n",
        "  validation_split = 0.2,\n",
        "  subset = \"training\",\n",
        "  seed = 123,\n",
        "  color_mode = 'rgb',\n",
        "  image_size = (dimension, dimension),\n",
        "  batch_size = batch_size\n",
        ")\n",
        "\n",
        "#Load test images\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  path,\n",
        "  validation_split = 0.2,\n",
        "  subset = \"validation\",\n",
        "  seed = 123,\n",
        "  color_mode = 'rgb', #'grayscale'\n",
        "  image_size = (dimension, dimension),\n",
        "  batch_size = batch_size\n",
        ")\n",
        "\n",
        "#Allows data to be extracted more easily and thus avoids blocking\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "#Create the model\n",
        "model = tf.keras.Sequential([ #Add the model layers\n",
        "    tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(dimension, dimension, 3)),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(2) #2 outputs for the 2 possibilities\n",
        "])\n",
        "\n",
        "#Compile the model\n",
        "model.compile(\n",
        "    optimizer = 'adam', #Model optimizer\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),   #Measures model accuracy\n",
        "    metrics = ['accuracy']   #Used to monitor training and test steps\n",
        ")\n",
        "\n",
        "#Display a summary of the model\n",
        "model.summary()\n",
        "\n",
        "\n",
        "#Train the model\n",
        "history = model.fit(\n",
        "            train_ds, #Training data\n",
        "            validation_data = val_ds, #Test data\n",
        "            epochs = 15 #Number of epochs\n",
        ")\n",
        "\n",
        "#Save the model\n",
        "model.save('model_reconize_screw_nut.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "AdJ7kpfyD5Jd",
        "outputId": "5dd48162-90eb-41ba-e185-2ad4a0f399c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "No such file: '/content/ecrou_1.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2296ea636fa8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Initialise et affiche l'image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                                (plugin, kind))\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/io/_plugins/imageio_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/v2.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0mimopen_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"legacy_mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mimopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ri\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mimopen_args\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/core/imopen.py\u001b[0m in \u001b[0;36mimopen\u001b[0;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_hint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_hint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_hint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"<bytes>\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, uri, mode, extension, format_hint, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# Parse what was given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# Set extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file: '/content/ecrou_1.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsLezsB_2Aad"
      },
      "source": [
        "# Model predictions\n",
        "\n",
        "Here, we decided to test out our code on an image database we previously built. This code loads the pre-trained model (that was previously trained in the machine learning part), and then uses the loaded model to make predictions on a test image of either a nut or a screw."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "CLASS_NAMES = ['nut', 'screw']\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load the previously trained model\n",
        "    model = tf.keras.models.load_model('model_reconize_screw_nut.h5')\n",
        "\n",
        "    # Image path\n",
        "    img_path = '0_data_base_bin_nut.png'\n",
        "    # Load the image to be tested\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = tf.keras.applications.vgg16.preprocess_input(img_array)\n",
        "\n",
        "    # Model predictions on the image\n",
        "    probability_model = tf.keras.Sequential([model,\n",
        "                                            tf.keras.layers.Softmax()]) # Output as probability\n",
        "    predictions = probability_model.predict(img_array) # Make a prediction on img_test\n",
        "\n",
        "    # Display the AI prediction\n",
        "    print(CLASS_NAMES[np.argmax(predictions[0])])"
      ],
      "metadata": {
        "id": "F19smO7U7_Tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "\n"
      ],
      "metadata": {
        "id": "fx4I1Wjh8bBZ"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}