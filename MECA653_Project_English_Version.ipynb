{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NuQten/Projet_IArecognizing_bolt_nut/blob/main/MECA653_Project_English_Version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW_ryhlz2AaY"
      },
      "source": [
        "# Automized Quality Control : an AI that recognizes a screw from a nut\n",
        "\n",
        "**Authors:  Elisa LABALLERY, BenoÃ®t DAVID, Quentin CONANEC**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvI-C-X52Aab"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "\n",
        "## Why this project ?\n",
        "\n",
        "\n",
        "This project can be very interesting regarding industrial applications.\n",
        "\n",
        "In fact, it could help automate quality control by ensuring that the right components are used and assembled by an accurate identification of, in this case, bolts and nuts.\n",
        "\n",
        "Besides, it can positivily develop inventory management : it is able to assist in keeping track of components in warehouses and reducing errors of misplacement or misidentification of tools.\n",
        "\n",
        "Finally, with no doubt, an AI brings efficiency gains. This project can lead to faster production and execution time, along as lower costs as it may work without fatigue.\n",
        "\n",
        "In addition, this project is obviously interesting in matter of Big Data applications. The ability to differentiate similar objects means the AI can process and learn from large datasets, improving over time and adapting to new specifications.\n",
        "\n",
        "\n",
        "## State of the art\n",
        "\n",
        "\n",
        "To modelize an IA working in a factory and trained to recognize bolts from nuts, we had to import a graphic database of different bolts and nuts. You will have to import this database in the files section \"content\" to get the code to work effectively.\n",
        "\n",
        "\n",
        "## Numerical challenges\n",
        "\n",
        "\n",
        "This project assesses three key points of coding : image processing, machine learning and prediction models.\n",
        "\n",
        "First, we will have to manipulate classes and functions to segment, normalize and binarize our imported images.\n",
        "\n",
        "Then, we are going to create a neural network model for classifying our images using transfer learning (with the VGG16 architecture).\n",
        "\n",
        "Finally, we are going to test our model on an image database. The predictions made by the model are based on the learned parameters of the neural network. If the model was not trained properly or if it has limitations in recognizing certain features of nuts and screws, the predictions may not be accurate.\n",
        "\n",
        "\n",
        "# Coding\n",
        "\n",
        "Now, we will guide you in the process of this coding project. First, please run these little modules so that everything is settled !"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import morphology, transform, feature, measure, segmentation, color, io, filters\n",
        "import skimage as ski\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy import ndimage\n",
        "import random\n"
      ],
      "metadata": {
        "id": "3z0EnuYf8a1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Processing\n",
        "\n",
        "First, let's get through the image processing part.\n",
        "\n",
        "The best way to deal with this task is to create a class.\n",
        "It's main purpose is to load images, convert them to grayscale, apply gradient filters, segment them based on pixel intensity, normalize the images to a specific dimension, and finally binarize them.\n",
        "\n",
        "This is useful, in particular, regarding the efficiency of the machine learning model we are going to create afterwards.\n",
        "\n",
        "Commentaries complete the code for further understanding."
      ],
      "metadata": {
        "id": "cWq2nCc-olQx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-F-ER4PP2Aac"
      },
      "outputs": [],
      "source": [
        "class Image_ia():\n",
        "\n",
        "    def __init__(self, path: str, seuil=0.025, dimension=100, label_bg=2, label_connect=2, distance_expanse=20) -> None:\n",
        "        \"\"\"Initializes the image to be used by the AI onwards.\n",
        "\n",
        "        Args:\n",
        "            path (str): Path to the image file.\n",
        "            seuil (float, optional): Threshold between background (bg) and foreground (fg). Value ranges between [0;1]. Defaults to 0.025.\n",
        "            label_bg (int, optional): Includes the background in the labeling or not. Acceptable values are {None, 1, 2}. Defaults to 2.\n",
        "            label_connect (int, optional): Number of pixels between two points to connect them together. Defaults to 2.\n",
        "            dimension (int, optional): Dimension of the final image. Defaults to 100.\n",
        "        \"\"\"\n",
        "        # Image Characteristics\n",
        "        self.path = path\n",
        "        self.seuil = seuil\n",
        "        self.dimension = dimension\n",
        "        self.label_bg = label_bg\n",
        "        self.label_connect = label_connect\n",
        "        self.distance_expanse = distance_expanse\n",
        "\n",
        "        # Different images\n",
        "        self.img_whole = ski.io.imread(path)\n",
        "        self.gray_img_whole = ski.color.rgb2gray(self.img_whole)\n",
        "        self.gradient_img_whole = ski.filters.sobel(self.gray_img_whole)\n",
        "        self.imgs = self.__segmentation()\n",
        "        self.gray_imgs = [ski.color.rgb2gray(img) for img in self.imgs]\n",
        "        self.normalize_gray_imgs = [transform.resize(img, (self.dimension, self.dimension), anti_aliasing=True) for img in self.gray_imgs]\n",
        "        self.normalize_gradient_imgs = [ski.filters.sobel(img) for img in self.normalize_gray_imgs]\n",
        "        self.normalize_bin_imgs = [bin_image(img) for img in self.normalize_gradient_imgs]\n",
        "\n",
        "    def __segmentation(self):\n",
        "        \"\"\"Divides the main image according to the number of parts present in the photo.\n",
        "\n",
        "        Returns:\n",
        "            list : Returns a list of different images.\n",
        "        \"\"\"\n",
        "        # Segment the image based on the gradient filter\n",
        "        labels = labelisation(self.gradient_img_whole, self.seuil, self.label_bg, self.label_connect)\n",
        "\n",
        "        # Remove labels\n",
        "        labels, enum_label = remove_label(labels)\n",
        "\n",
        "        # Expand the labels\n",
        "        label_expanded = ski.segmentation.expand_labels(labels, distance=self.distance_expanse)\n",
        "\n",
        "        # Create images of different labels\n",
        "        imgs = create_img_label(label_expanded, enum_label, self.img_whole)\n",
        "        for img in imgs:  # Iterate through the different images to remove the useless ones (black/white)\n",
        "            if img.max == 0 or img.min == 255:\n",
        "                imgs.remove(img)\n",
        "\n",
        "        # Return the images of different labels\n",
        "        return imgs\n",
        "\n",
        "\n",
        "def labelisation(img, seuil=0.025, label_bg=2, label_connect=2):\n",
        "    \"\"\"Differentiates the different zones of each component.\n",
        "\n",
        "    Args:\n",
        "        img (array): image filtered with the Sobel filter\n",
        "        seuil (float, optional): Threshold between bg and fg. Value ranges between [0;1]. Defaults to 0.025.\n",
        "        label_bg (int, optional): Includes the bg in the labeling or not. Acceptable values are {None, 1, 2}. Defaults to 2.\n",
        "        label_connect (int, optional): Number of pixels between two points to connect them together. Defaults to 2.\n",
        "\n",
        "    Returns:\n",
        "        array : Returns an image with different labels.\n",
        "    \"\"\"\n",
        "    # Create an image of the same size\n",
        "    markers = np.zeros_like(img)\n",
        "\n",
        "    # Identify the foreground and background using the chosen threshold\n",
        "    foreground, background = 1, 2\n",
        "    markers[img < seuil] = background\n",
        "    markers[img > seuil] = foreground\n",
        "\n",
        "    # Apply segmentation\n",
        "    segmentation_result = ski.segmentation.watershed(img, markers)\n",
        "\n",
        "    # Identify the different labels\n",
        "    labels = measure.label(segmentation_result == foreground, background=label_bg, connectivity=label_connect)\n",
        "\n",
        "    # Return an image with the labels\n",
        "    return labels\n",
        "\n",
        "\n",
        "def remove_label(labels, pixel_min=1000):\n",
        "    \"\"\"Removes labels that are too small.\n",
        "\n",
        "    Args:\n",
        "        labels (array): image of different labels\n",
        "        pixel_min (int, optional): minimum number of pixels required to keep a label. Defaults to 1000.\n",
        "    Returns:\n",
        "        (array, dict) : Returns an image with labels removed and a dictionary with their characteristics.\n",
        "    \"\"\"\n",
        "    # Basic characteristics\n",
        "    enum_label = {}  # Store the characteristics of the labels\n",
        "    x, y = labels.shape  # Dimensions of the image\n",
        "    get_number = True  # Check if the label exists\n",
        "    n = 0  # Number of points\n",
        "    is_number = 1  # Define the label to be tested\n",
        "\n",
        "    # Loop through the labels one by one\n",
        "    while get_number == True:\n",
        "        list_i = []  # List of pixels in i\n",
        "        list_j = []  # List of pixels in j\n",
        "        n = 0       # Number of pixels\n",
        "\n",
        "        for i in range(x):  # Loop through the image of labels\n",
        "            for j in range(y):\n",
        "                if labels[i][j] == is_number:  # Check if the pixel belongs to the label\n",
        "                    # Add the pixel to the list\n",
        "                    n += 1\n",
        "                    list_i.append(i)\n",
        "                    list_j.append(j)\n",
        "\n",
        "        if n == 0:  # If 0 points detected, then there are no more labels, close the loop\n",
        "            get_number = False\n",
        "        elif n <= pixel_min:  # If fewer pixels than desired, then delete the label\n",
        "            for i, j in zip(list_i, list_j):\n",
        "                labels[i][j] = 0\n",
        "        else:  # Otherwise, store the characteristics of the label\n",
        "            enum_label[is_number] = {'i_min': min(list_i),\n",
        "                                     'i_max': max(list_i),\n",
        "                                     'j_min': min(list_j),\n",
        "                                     'j_max': max(list_j),\n",
        "                                     'nb_point': n\n",
        "                                    }\n",
        "\n",
        "        # Increment by 1 to test the next label\n",
        "        is_number += 1\n",
        "\n",
        "    return labels, enum_label  # Return the remaining labels and their characteristics\n",
        "\n",
        "\n",
        "def create_img_label(labels, enum_label, image):\n",
        "    \"\"\"Creates a new image for each label and returns a list of them.\n",
        "\n",
        "        Args:\n",
        "            enum_label (dict): characteristics of each label\n",
        "            label_expanded (array): image of desired labels\n",
        "\n",
        "        Returns:\n",
        "            list : Returns a list of new images.\n",
        "    \"\"\"\n",
        "    # Create the list that will contain the future images\n",
        "    new_pict = []\n",
        "\n",
        "    # Loop for the number of labels (and therefore photos)\n",
        "    for number_label, label in enum_label.items():\n",
        "\n",
        "        dimension = max(label['i_max']-label['i_min'],  # Get the dimensions of the future image\n",
        "                        label['j_max']-label['j_min'])\n",
        "        segmented_image = np.zeros((dimension, dimension, 3), dtype='uint8')  # Create a black image with the dimensions\n",
        "\n",
        "        # Replace the black image with the desired one\n",
        "        for i in range(label['i_min'], label['i_max']):  # Iterate through the location of the image in the base one\n",
        "            for j in range(label['j_min'], label['j_max']):\n",
        "                if labels[i][j] != number_label:  # If the pixel does not belong to the label, then make it black\n",
        "                    segmented_image[i - label['i_min']][j - label['j_min']] = np.array([0, 0, 0], dtype='uint8')\n",
        "                else:  # Otherwise, it takes the value of the initial image\n",
        "                    segmented_image[i - label['i_min']][j - label['j_min']] = image[i][j]\n",
        "\n",
        "        # Replace the black pixels to obtain a uniform background\n",
        "        for i in range(dimension):\n",
        "            for j in range(dimension):\n",
        "                if np.array_equal(segmented_image[i][j], np.array([0, 0, 0]), equal_nan=False):\n",
        "                    if i == 0:\n",
        "                        segmented_image[i][j] = segmented_image[i][j-1]\n",
        "                    elif j == 0:\n",
        "                        segmented_image[i][j] = segmented_image[i-1][j]\n",
        "                    else:\n",
        "                        segmented_image[i][j] = segmented_image[i-1][j-1]\n",
        "\n",
        "        # Add the image to the list of images\n",
        "        new_pict.append(segmented_image)\n",
        "\n",
        "    # Return the list of images\n",
        "    return new_pict\n",
        "\n",
        "\n",
        "def bin_image(img, seuil=0.025):\n",
        "    \"\"\"Binarizes an image.\n",
        "\n",
        "    Args:\n",
        "        img (array): image to binarize\n",
        "        seuil (float, optional): Binarization threshold [0;1]. Defaults to 0.025.\n",
        "\n",
        "    Returns:\n",
        "        array : Returns a binarized image.\n",
        "    \"\"\"\n",
        "    # Create an image of the same size\n",
        "    markers = np.zeros_like(img)\n",
        "\n",
        "    # Identify the foreground and background using the chosen threshold\n",
        "    foreground, background = 1, 2\n",
        "    markers[img < seuil] = background\n",
        "    markers[img > seuil] = foreground\n",
        "\n",
        "    # Apply binarization\n",
        "    img_watershed = ski.segmentation.watershed(img, markers)\n",
        "\n",
        "    # Iterate through the image\n",
        "    for i in range(img_watershed.shape[0]):\n",
        "        for j in range(img_watershed.shape[1]):\n",
        "            if img_watershed[i][j] == 2:  # If the pixel belongs to the foreground, make it black\n",
        "                img_watershed[i][j] = 1.\n",
        "            else:  # If the pixel belongs to the background, make it white\n",
        "                img_watershed[i][j] = 0.\n",
        "\n",
        "    # Return the binarized image\n",
        "    return img_watershed\n",
        "\n",
        "\n",
        "def list_files_recursively(directory):\n",
        "    \"\"\"Returns a list of files present in the hierarchy\n",
        "    starting from the access path.\n",
        "    \"\"\"\n",
        "    list_path = []\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            list_path.append(os.path.join(root, file))\n",
        "    return list_path\n",
        "\n",
        "\n",
        "def save_normalize_bin_img(path, dimension):\n",
        "    \"\"\"Saves all the photos in a dimension from\n",
        "        the image files found in the hierarchy.\n",
        "    \"\"\"\n",
        "    # List of all access paths to an image\n",
        "    liste = list_files_recursively(path)\n",
        "\n",
        "    nut = 1\n",
        "    screw = 1\n",
        "    os.mkdir(f'data_base_bin_{dimension}')\n",
        "    os.mkdir(f'data_base_bin_{dimension}/screws')\n",
        "    os.mkdir(f'data_base_bin_{dimension}/nuts')\n",
        "\n",
        "    for path in liste:\n",
        "        img = Image_ia(path, dimension=dimension)\n",
        "        for bin in img.normalize_bin_imgs:\n",
        "            # Save the binary image\n",
        "            if \"screws\" in path:\n",
        "                name = f'data_base_bin_{dimension}/screws/{screw}_img_bin_screw_{dimension}.png'\n",
        "                ski.io.imsave(name, (bin * 255).astype('uint8'))\n",
        "                screw += 1\n",
        "            else:\n",
        "                name = f'data_base_bin_{dimension}/nuts/{nut}_img_bin_nut_{dimension}.png'\n",
        "                ski.io.imsave(name, (bin * 255).astype('uint8'))\n",
        "                nut += 1\n",
        "            print(name)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    path = 'boulon_entier.jpg'  # Access path of the image\n",
        "    img = Image_ia(path)\n",
        "\n",
        "    # Display all states of the image\n",
        "    plt.figure()\n",
        "    plt.title('whole image (color)')\n",
        "    plt.imshow(img.img_whole)\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title('whole image (gray)')\n",
        "    plt.imshow(img.gray_img_whole, cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title('whole image (gradient)')\n",
        "    plt.imshow(img.gradient_img_whole, cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title('segmented image (color)')\n",
        "    plt.imshow(img.imgs[0])\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title('segmented image (gray)')\n",
        "    plt.imshow(img.gray_imgs[0], cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title('segmented normalized image (gray)')\n",
        "    plt.imshow(img.normalize_gray_imgs[0], cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title('segmented normalized image (gradient)')\n",
        "    plt.imshow(img.normalize_gradient_imgs[0], cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title('segmented normalized image (binary)')\n",
        "    plt.imshow(img.normalize_bin_imgs[0], cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "    # Save all images in a dimension\n",
        "    path = 'data_base'  # Access path of the images\n",
        "    save_normalize_bin_img(path, 224)  # Save the images in a folder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine learning\n",
        "\n",
        "Now, we have to create an AI that manages to recognizes a screw from a nut and automatically saves the image in a folder regarding wether it's one or another.\n",
        "\n",
        "This code defines, trains, and evaluates a neural network model for classifying our images using transfer learning with the VGG16 architecture.\n",
        "\n",
        "To be precise, a neural network is very useful in machine learning as it is effective for image classification tasks. Besides, the VGG16 architecure contains 16 layers and the last layers are removed, so that new layers are added for classifying nuts and screws specifically, leading to an ability to extract useful feature whilst adapting it to our specific case.\n",
        "\n",
        "Please find useful commentary in the code for further understanding.\n",
        "P.S : This module may take quite a few minutes to be fully ran, please be patient !"
      ],
      "metadata": {
        "id": "irRuOOkZ0zZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "CLASS_NAMES = ['nut', 'screw'] #List of possibilities\n",
        "dimension = 224 #Image dimension\n",
        "batch_size = 32\n",
        "path = f'data_base_color_{dimension}' #Path to the database\n",
        "\n",
        "#Load training images\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  path,\n",
        "  validation_split = 0.2,\n",
        "  subset = \"training\",\n",
        "  seed = 123,\n",
        "  color_mode = 'rgb',\n",
        "  image_size = (dimension, dimension),\n",
        "  batch_size = batch_size\n",
        ")\n",
        "\n",
        "#Load test images\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  path,\n",
        "  validation_split = 0.2,\n",
        "  subset = \"validation\",\n",
        "  seed = 123,\n",
        "  color_mode = 'rgb', #'grayscale'\n",
        "  image_size = (dimension, dimension),\n",
        "  batch_size = batch_size\n",
        ")\n",
        "\n",
        "#Allows data to be extracted more easily and thus avoids blocking\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "#Create the model\n",
        "model = tf.keras.Sequential([ #Add the model layers\n",
        "    tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(dimension, dimension, 3)),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(2) #2 outputs for the 2 possibilities\n",
        "])\n",
        "\n",
        "#Compile the model\n",
        "model.compile(\n",
        "    optimizer = 'adam', #Model optimizer\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),   #Measures model accuracy\n",
        "    metrics = ['accuracy']   #Used to monitor training and test steps\n",
        ")\n",
        "\n",
        "#Display a summary of the model\n",
        "model.summary()\n",
        "\n",
        "\n",
        "#Train the model\n",
        "history = model.fit(\n",
        "            train_ds, #Training data\n",
        "            validation_data = val_ds, #Test data\n",
        "            epochs = 15 #Number of epochs\n",
        ")\n",
        "\n",
        "#Save the model\n",
        "model.save('model_reconize_screw_nut.h5')"
      ],
      "metadata": {
        "id": "AdJ7kpfyD5Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsLezsB_2Aad"
      },
      "source": [
        "# Model predictions\n",
        "\n",
        "Here, we decided to test out our code on an image database we previously built. This code loads the pre-trained model (that was previously trained in the machine learning part), and then uses the loaded model to make predictions on a test image of either a nut or a screw."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "CLASS_NAMES = ['nut', 'screw']\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load the previously trained model\n",
        "    model = tf.keras.models.load_model('model_reconize_screw_nut.h5')\n",
        "\n",
        "    # Image path\n",
        "    img_path = '0_data_base_bin_nut.png'\n",
        "    # Load the image to be tested\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = tf.keras.applications.vgg16.preprocess_input(img_array)\n",
        "\n",
        "    # Model predictions on the image\n",
        "    probability_model = tf.keras.Sequential([model,\n",
        "                                            tf.keras.layers.Softmax()]) # Output as probability\n",
        "    predictions = probability_model.predict(img_array) # Make a prediction on img_test\n",
        "\n",
        "    # Display the AI prediction\n",
        "    print(CLASS_NAMES[np.argmax(predictions[0])])"
      ],
      "metadata": {
        "id": "F19smO7U7_Tp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c62d529c-2e7d-43af-c559-d5777a091681"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 703ms/step\n",
            "screw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "\n",
        "Overall, these codes form a complete pipeline for image classification, starting from image preprocessing and model training to making predictions on new images. The result will be the predicted class (either 'nut' or 'screw') for each input image, giving a trusted result to the user.\n"
      ],
      "metadata": {
        "id": "fx4I1Wjh8bBZ"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}